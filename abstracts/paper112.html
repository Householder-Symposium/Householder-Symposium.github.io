---
layout: abstract
absnum: 112
---
{% raw %}

<div data-nosnippet
    style="display:none"
>

\(\newcommand{\footnotename}{footnote}\)

\(\def \LWRfootnote {1}\)

\(\newcommand {\footnote }[2][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\newcommand {\footnotemark }[1][\LWRfootnote ]{{}^{\mathrm {#1}}}\)

\(\let \LWRorighspace \hspace \)

\(\renewcommand {\hspace }{\ifstar \LWRorighspace \LWRorighspace }\)

\(\newcommand {\mathnormal }[1]{{#1}}\)

\(\newcommand \ensuremath [1]{#1}\)

\(\newcommand {\LWRframebox }[2][]{\fbox {#2}} \newcommand {\framebox }[1][]{\LWRframebox } \)

\(\newcommand {\setlength }[2]{}\)

\(\newcommand {\addtolength }[2]{}\)

\(\newcommand {\setcounter }[2]{}\)

\(\newcommand {\addtocounter }[2]{}\)

\(\newcommand {\arabic }[1]{}\)

\(\newcommand {\number }[1]{}\)

\(\newcommand {\noalign }[1]{\text {#1}\notag \\}\)

\(\newcommand {\cline }[1]{}\)

\(\newcommand {\directlua }[1]{\text {(directlua)}}\)

\(\newcommand {\luatexdirectlua }[1]{\text {(directlua)}}\)

\(\newcommand {\protect }{}\)

\(\def \LWRabsorbnumber #1 {}\)

\(\def \LWRabsorbquotenumber &quot;#1 {}\)

\(\newcommand {\LWRabsorboption }[1][]{}\)

\(\newcommand {\LWRabsorbtwooptions }[1][]{\LWRabsorboption }\)

\(\def \mathchar {\ifnextchar &quot;\LWRabsorbquotenumber \LWRabsorbnumber }\)

\(\def \mathcode #1={\mathchar }\)

\(\let \delcode \mathcode \)

\(\let \delimiter \mathchar \)

\(\def \oe {\unicode {x0153}}\)

\(\def \OE {\unicode {x0152}}\)

\(\def \ae {\unicode {x00E6}}\)

\(\def \AE {\unicode {x00C6}}\)

\(\def \aa {\unicode {x00E5}}\)

\(\def \AA {\unicode {x00C5}}\)

\(\def \o {\unicode {x00F8}}\)

\(\def \O {\unicode {x00D8}}\)

\(\def \l {\unicode {x0142}}\)

\(\def \L {\unicode {x0141}}\)

\(\def \ss {\unicode {x00DF}}\)

\(\def \SS {\unicode {x1E9E}}\)

\(\def \dag {\unicode {x2020}}\)

\(\def \ddag {\unicode {x2021}}\)

\(\def \P {\unicode {x00B6}}\)

\(\def \copyright {\unicode {x00A9}}\)

\(\def \pounds {\unicode {x00A3}}\)

\(\let \LWRref \ref \)

\(\renewcommand {\ref }{\ifstar \LWRref \LWRref }\)

\( \newcommand {\multicolumn }[3]{#3}\)

\(\require {textcomp}\)

\(\newcommand {\intertext }[1]{\text {#1}\notag \\}\)

\(\let \Hat \hat \)

\(\let \Check \check \)

\(\let \Tilde \tilde \)

\(\let \Acute \acute \)

\(\let \Grave \grave \)

\(\let \Dot \dot \)

\(\let \Ddot \ddot \)

\(\let \Breve \breve \)

\(\let \Bar \bar \)

\(\let \Vec \vec \)

\(\newcommand {\bm }[1]{\boldsymbol {#1}}\)

</div>

<a id="paper-autopage-1"></a>
<div class="center">

<h2>
Towards Eﬀicient Algorithms for Approximately Solving (Overdetermined) Systems of Polynomial Equations
</h2>
</div>
<div class="center">

<p>
<span class="underline">N. Govindarajan</span>, R. Widdershoven, L. De Lathauwer
</p>
</div>
<div class="center">

<p>
Abstract
</p>
</div>

<p>
We revisit the age-old problem of solving a system of multivariate polynomial equations. This problem can be viewed as a simultaneous generalization of solving linear systems and finding roots of univariate polynomials. It is well-known that the
aforementioned special cases have widespread applications in science and engineering. It should come as no surprise that the same is true about the more general version of this problem. This is particularly the case in the noisy overdetermined
setting, which extends the familiar engineering notion of solving a system of linear equations in a “least-squares” fashion to the polynomial case.
</p>

<p>
Classically, solving a system of polynomial equations belongs to the field of computational algebraic geometry. The literature advocates two major approaches to the problem. The first approach involves homotopy continuation, where the roots of the
desired system are found by continuous deformation of a starting system for which the roots are already known. The second approach, which is more in line with our work, reduces the problem to an eigenvalue problem. The algebraic approach has its
origins in resultant theory, tracing back to original contributions by B’ezout, Sylvester, Cayley, and Macaulay. The main idea behind this line of attack is to unveil the structure of the quotient algebra of the ideal generated by the polynomial system.
Solutions of the system are subsequently extracted from the eigen-structure of the generated multiplication tables [1].
</p>

<p>
Up to this point, the literature has primarily focused on the noiseless square case. Herein, it is assumed that the coeﬀicients of the polynomials are known with full precision and the number of equations equals the number of unknowns. On the
contrary, a critical component of engineering applications is the estimation of system parameters from an overcomplete set of equations corrupted by noise. In the case of linear systems, numerical linear algebra already provides effective methods to
deal with such problems. Analogous methods to treat the more general polynomial case are, however, far fewer, and relatively underdeveloped.
</p>

<p>
Our work hopes to fill this gap by taking a fresh perspective on the problem. The cornerstone of our proposed framework is the (tensor-based) Macaulay method [4]. This method rests on the idea that a basis for the quotient algebra can be formed
by computing a numerical null space of a resultant map. The classical Macaulay matrix, which generalizes the Sylvester resultant matrix of two univariate polynomials to the multivariate case, is a canonical example of such a map. The fact that the
null space is obtained through numerical means is an essential ingredient in enabling the solvability of polynomial systems in an approximate sense [5].
</p>

<p>
This core key feature of the methodology is best explained through an example. Suppose that one wants to solve the overdetermined linear system
</p>

<p>
\[\left [ \begin {array}{c|cc} -3 &amp; -1 &amp; -2 \\ -2 &amp; -1 &amp; 1 \\ 1 &amp; 7 &amp; 1 \end {array}\right ] \left [ \begin {array}{c} 1 \\ \hline x \\ y \end {array} \right ] = \left [ \begin {array}{c} 0
\\ 0 \\ 0 \end {array} \right ]\]
</p>

<p>
in a total least-squares sense. As it is well-known, the solution is trivially found by retrieving the smallest right-singular vector of the matrix on the left-hand side of the expression. Since the corresponding singular value is strictly positive, the
right-singular vector (after normalization) will only yield an approximate solution of the system. Interesetingly, a similar strategy may be employed to find approximate solutions for polynomial systems. For example, the overdetermined polynomial
system
</p>

<span class="hidden"> \(\seteqnumber{0}{}{0}\)</span>

<!--

                                                                                                                                                               
                                                                                                                                                              1
                                                                                                                                                          x      
                                                                                                     p1 (x,y)     −3       −1         −2      4    6    7  y 
                                                                                                                                                                   0
                                                                                                     p2 (x,y)    −2       −1         1       3    −7   5       0 
                                                                                                                                                            x2  =                                                        (1)--><a id="eq:poly"></a><!--
                                                                                                                   1        7         1      −8    3    1        0
                                                                                                                                                             xy 
                                                                                                     p3 (x,y)

                                                                                                                                                                 y2

-->

<p>

\begin{equation}
\begin{array}{c} \scriptstyle p_1(x,y)\\ \scriptstyle p_2(x,y)\\ \scriptstyle p_3(x,y) \end {array} \left [ \begin{array}{c|cc|ccc} -3 &amp; -1 &amp; -2 &amp; 4 &amp; 6 &amp; 7 \\ -2 &amp; -1 &amp; 1 &amp; 3 &amp;
-7 &amp; 5 \\ 1 &amp; 7 &amp; 1 &amp; -8 &amp; 3 &amp; 1 \end {array} \right ] \left [ \begin{array}{c} 1 \\ \hline x \\ y \\\hline x^2 \\ xy \\ y^2 \end {array} \right ] = \left [ \begin{array}{c} 0 \\ 0 \\ 0 \end
{array} \right ] \label {eq:poly}
\end{equation}

</p>

<p>
has an exact solution at \((x,y) = (1,0)\), which is also the only solution of the system. This single solution disappears under small perturbations of the coeﬀicients, but one can still view \((x,y) = (1,0)\) as an approximate solution of the
noise-perturbed system. After all, the Vandermonde vector evaluated at this point, i.e., \(\begin {bmatrix} 1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 \end {bmatrix}^{\top }\), is still an approximate null vector for the noise perturbed
matrix. It can therefore be subsequently used to derive approximate solutions.
</p>

<p>
Unlike the linear system, there are several complications that one has to treat in the polynomial case. Firstly, the existence of other artificial null vectors in <span class="textup">(<a href="paper.html#eq:poly">1</a>)</span> make the retrieval
of the Vandermonde solution vector impossible. This first complication is resolved by adding additional equations to the system:
</p>

<span class="hidden"> \(\seteqnumber{0}{}{1}\)</span>

<!--

                                                                                                                                                                                
                                                                                                                                                                           1        
                                                                                     p1 (x,y)      −3      −1       −2     4         6      7     0     0    0        0            0
                                                                                                  −2                                                                        x
                                                                                     p2 (x,y)
                                                                                                          −1       1      3         −7     5     0     0    0        0         
                                                                                                                                                                         y   0 
                                                                                                                                                                                       
                                                                                                  1        7       1      −8        3      1     0     0    0        0   2   0 
                                                                                     p3 (x,y)
                                                                                                                                                                        x         
                                                                                                  0       −3       0      −1        −2     0     4     6    7        0            
                                                                                     xp1 (x,y)
                                                                                                                                                                         xy   0 
                                                                                                  0       −2       0      −1        1      0     3     −7   5        0   2  =  0 .
                                                                                     xp2 (x,y)
                                                                                                                                                                        y         
                                                                                                  0        1       0      7         1      0     −8    3    1        0            
                                                                                     xp3 (x,y)
                                                                                                                                                                         x3   0 
                                                                                                  0        0       −3     0         −1     −2    0     4    6        7          0 
                                                                                     yp1 (x,y)                                                                           x2 y     
                                                                                     yp2 (x,y)    0        0       −2     0         −1     1     0     3    −7       5          0 
                                                                                                                                                                           xy 2 
                                                                                     yp3 (x,y)      0       0       1      0         7      1     0     −8   3        1              0
                                                                                                                                                                             y3

-->

<p>

\begin{equation*}
\begin{array}{c} \scriptstyle p_1(x,y)\\ \scriptstyle p_2(x,y)\\ \scriptstyle p_3(x,y)\\ \scriptstyle xp_1(x,y)\\ \scriptstyle xp_2(x,y)\\ \scriptstyle xp_3(x,y)\\ \scriptstyle yp_1(x,y)\\ \scriptstyle yp_2(x,y)\\
\scriptstyle yp_3(x,y)\\ \end {array} \left [ \begin{array}{c|cc|ccc|cccc} -3 &amp; -1 &amp; -2 &amp; 4 &amp; 6 &amp; 7 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\ -2 &amp; -1 &amp; 1 &amp; 3 &amp; -7 &amp; 5 &amp; 0 &amp;
0 &amp; 0 &amp; 0\\ 1 &amp; 7 &amp; 1 &amp; -8 &amp; 3 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\ \hline 0 &amp; -3 &amp; 0 &amp; -1 &amp; -2 &amp; 0 &amp; 4 &amp; 6 &amp; 7 &amp; 0 \\ 0 &amp; -2 &amp; 0 &amp; -1
&amp; 1 &amp; 0 &amp; 3 &amp; -7 &amp; 5 &amp; 0 \\ 0 &amp; 1 &amp; 0 &amp; 7 &amp; 1 &amp; 0 &amp; -8 &amp; 3 &amp; 1 &amp; 0 \\ \hline 0 &amp; 0 &amp; -3 &amp; 0 &amp; -1 &amp; -2 &amp; 0 &amp; 4 &amp; 6 &amp;
7\\ 0 &amp; 0 &amp; -2 &amp; 0 &amp; -1 &amp; 1 &amp; 0 &amp; 3 &amp; -7 &amp; 5\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; 7 &amp; 1 &amp; 0 &amp; -8 &amp; 3 &amp; 1\\ \end {array} \right ] \left [ \begin{array}{c} 1 \\
\hline x \\ y \\\hline x^2 \\ xy \\ y^2 \\\hline x^3 \\ x^2y \\ xy^2 \\ y^3 \end {array} \right ] = \left [ \begin{array}{c} 0 \\ 0 \\ 0 \\\hline 0 \\ 0 \\ 0 \\\hline 0 \\ 0 \\ 0 \end {array} \right ].
\end{equation*}

</p>

<p>
The above matrix presents an example of a Macaulay matrix at a certain degree. This Macaulay matrix contains the Vandermonde Vector
</p>

<p>
\[\left [\begin {array}{c|cc|ccc|cccc} 1 &amp; 1 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 \end {array}\right ]^{\top }\]
</p>

<p>
as the only null vector up to scaling ambiguity. Secondly, a polynomial system can, in general, admit multiple solutions. Consequently, the numerically obtained (approximate) null basis will not be immediately in Vandermonde form. This second
complication is resolved by performing an additional unmixing operation to retrieve the Vandermonde basis. This Vandermonde basis reconstruction can be viewed as a multi-dimensional harmonic retrieval problem [3], and can be effectively solved
by computing a canonical polyadic decomposition of a tensor formed from the obtained null space basis [4].
</p>

<p>
In general, solutions for a polynomial system can be determined in two computational steps: (i) compute the null space of the Macaulay matrix, and (ii) compute a polyadic decomposition of a tensor to retrieve the solutions. In the case of
overdetermined systems that only possess a handful of solutions, the first step is a major computational bottleneck. Macaulay matrices grow very rapidly in size for even moderately-sized polynomial systems. This makes the null space computation
prohibitively expensive. To get an impression of the complexity, a polynomial in \(N\) variables of degree \(D\) contains \(N+D \choose N\) monomial terms. The Macaulay matrix at degree \(D_{\mathrm {mac}} \geq D\) of \(S\) such polynomials
is the matrix that is constructed from the polynomial coeﬀicients of the system \(\lbrace p_s\rbrace ^{S}_{s=1}\) such that its rows span the set of polynomials
</p>

<span class="hidden"> \(\seteqnumber{0}{}{1}\)</span>

<!--

                                                                                                                    {                                             }
                                                                                                                               ∑
                                                                                                                               S
                                                                                                                        p :=         hs · p s :   deg(p) ≤ Dmac       .                                                                                    (2)
                                                                                                                               s=1


-->

<p>

\begin{equation}
\left \lbrace p:= \sum ^S_{s=1} h_s \cdot p_s: \quad \operatorname {deg}(p) \leq D_{\mathrm {mac}} \right \rbrace .
\end{equation}

</p>

<p>
Both the numbers of rows and columns of this matrix grow combinatorially in size with respect to \(D_{\mathrm {mac}}\), \(D\), and \(N\).
</p>

<p>
Fortunately, the Macaulay matrix is highly structured. In the monomial basis, the Macaulay matrix possesses multilevel Toeplitz structures. It also has recursive properties, and in certain cases, the matrix can be highly sparse. Furthermore, the
Chebyshev variant of the Macaulay matrix is multilevel Toeplitz-plus-Hankel. Subsequently, much of our research has been dedicated to developing eﬀicient null-space computation algorithms that exploit the structures in the matrix. Our efforts in
this area have led to some interesting work; some of which is still ongoing research:
</p>
<ul class="enumerate" style="list-style-type:none">

<li>
<p>
<span class="listmarker">1.</span> In [2] we considered exploiting the low-displacement rank structure of the Macaulay matrix to compute the null space through a rank-revealing LU factorization using the Gohberg-Kailath-Olshevsky (GKO)
algorithm. Although this approach reduced the memory and time complexity of the null-space computation significantly, the savings do not scale well for polynomial systems in many variables.
</p>

</li>
<li>

<p>
<span class="listmarker">2.</span> In recent (almost completed) work [6], we introduced an alternative approach that exploits the shift structure of the Macaulay matrix in a different way. This method scales more gracefully with the number of
variables. The method relies on computing the null spaces of nested subblocks of increasing size by using the fact that the same subblocks are repeated throughout the Macaulay matrix and that the null space of two stacked (block-)rows equals the
intersection of their individual null spaces.
</p>

</li>
<li>

<p>
<span class="listmarker">3.</span> Currently, we are also investigating an approach to compute the null space with a Krylov-based iterative technique. This option seems to be particularly attractive for overdetermined systems that only have a
few (approximate) solutions. This is because, in this case, the Macaulay matrix will have a relatively small (numerical) null space. In the monomial basis, the Macaulay matrix has fast matrix-vector product with the help of fast Fourier transforms.
Interestingly, one can also obtain a fast matrix-vector product for the Macaulay matrix in the Chebyshev basis using fast cosine transforms. A big challenge is to make the Krylov-based method converge in a reasonable number of iterations. Finding
good preconditioners may be essential.
</p>
</li>
</ul>

<p>
At the Householder Symposium, our goal is to share this research with our colleagues.
</p>
<!--
...... section References ......
-->
<h4 id="autosec-5">References</h4>
<a id="paper-autopage-5"></a>


<ul class="list" style="list-style-type:none">

<li>
<p>
<span class="listmarker">[1]&#x2003;</span> David&nbsp;A Cox. Stickelberger and the eigenvalue theorem. In <i>Commutative Algebra</i>, pages 283–298. Springer, 2021.
</p>
</li>
<li>

<p>
<span class="listmarker">[2]&#x2003;</span> Nithin Govindarajan, Raphaël Widdershoven, Shivkumar Chandrasekaran, and Lieven De&nbsp;Lathauwer. A fast algorithm for computing macaulay null spaces of bivariate polynomial systems.
<i>SIAM J. Matrix Anal. Appl.</i>, 45(1):368–396, 2024.
</p>
</li>
<li>

<p>
<span class="listmarker">[3]&#x2003;</span> M.&nbsp;Sørensen and L.&nbsp;De&nbsp;Lathauwer. Multidimensional harmonic retrieval via coupled canonical polyadic decomposition — Part I: Model and identifiability. <i>IEEE Transactions on
Signal Processing</i>, 65(2):517–527, 1 2017.
</p>
</li>
<li>

<p>
<span class="listmarker">[4]&#x2003;</span> Jeroen Vanderstukken and Lieven De&nbsp;Lathauwer. Systems of polynomial equations, higher-order rensor decompositions and multidimensional harmonic retrieval: A unifying framework. Part I:
The canonical polyadic decomposition. <i>SIAM J. Matrix Anal. Appl.</i>, 42(2):883–912, 2021.
</p>
</li>
<li>

<p>
<span class="listmarker">[5]&#x2003;</span> Raphaël Widdershoven, Nithin Govindarajan, and Lieven De&nbsp;Lathauwer. Overdetermined systems of polynomial equations: tensor-based solution and application. In <i>2023 31st European
Signal Processing Conference (EUSIPCO)</i>, pages 650–654. IEEE, 2023.
</p>
</li>
<li>

<p>
<span class="listmarker">[6]&#x2003;</span> Raphaël Widdershoven, Nithin Govindarajan, and Lieven De&nbsp;Lathauwer. Fast macaulay null space through the intersection of shifted null spaces. <i>Technical Report 25-56, ESAT-STADIUS,
KU&nbsp;Leuven (Leuven, Belgium)</i>, 2025.
</p>
<p>

</p>
</li>
</ul>

{% endraw %}
